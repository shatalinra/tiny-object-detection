2020-10-06 18:25:20,490: <INFO> Training autoencoder v3: attempt 0
2020-10-06 18:25:20,491: <INFO> Model: "autoencoder-v3"
2020-10-06 18:25:20,492: <INFO> _________________________________________________________________
2020-10-06 18:25:20,493: <INFO> Layer (type)                 Output Shape              Param #   
2020-10-06 18:25:20,494: <INFO> =================================================================
2020-10-06 18:25:20,496: <INFO> conv1 (Conv2D)               (None, 32, 32, 4)         52        
2020-10-06 18:25:20,496: <INFO> _________________________________________________________________
2020-10-06 18:25:20,497: <INFO> conv1-leaky (LeakyReLU)      (None, 32, 32, 4)         0         
2020-10-06 18:25:20,499: <INFO> _________________________________________________________________
2020-10-06 18:25:20,500: <INFO> conv2 (Conv2D)               (None, 16, 16, 10)        170       
2020-10-06 18:25:20,501: <INFO> _________________________________________________________________
2020-10-06 18:25:20,501: <INFO> conv2-leaky (LeakyReLU)      (None, 16, 16, 10)        0         
2020-10-06 18:25:20,502: <INFO> _________________________________________________________________
2020-10-06 18:25:20,503: <INFO> conv3 (Conv2D)               (None, 8, 8, 20)          820       
2020-10-06 18:25:20,503: <INFO> _________________________________________________________________
2020-10-06 18:25:20,504: <INFO> conv3-leaky (LeakyReLU)      (None, 8, 8, 20)          0         
2020-10-06 18:25:20,504: <INFO> _________________________________________________________________
2020-10-06 18:25:20,505: <INFO> deconv3 (Conv2DTranspose)    (None, 16, 16, 10)        810       
2020-10-06 18:25:20,506: <INFO> _________________________________________________________________
2020-10-06 18:25:20,507: <INFO> deconv3-leaky (LeakyReLU)    (None, 16, 16, 10)        0         
2020-10-06 18:25:20,507: <INFO> _________________________________________________________________
2020-10-06 18:25:20,508: <INFO> deconv2 (Conv2DTranspose)    (None, 32, 32, 4)         164       
2020-10-06 18:25:20,509: <INFO> _________________________________________________________________
2020-10-06 18:25:20,510: <INFO> deconv2-leaky (LeakyReLU)    (None, 32, 32, 4)         0         
2020-10-06 18:25:20,510: <INFO> _________________________________________________________________
2020-10-06 18:25:20,511: <INFO> deconv1 (Conv2DTranspose)    (None, 64, 64, 3)         51        
2020-10-06 18:25:20,512: <INFO> _________________________________________________________________
2020-10-06 18:25:20,512: <INFO> deconv1-sigmoid (Activation) (None, 64, 64, 3)         0         
2020-10-06 18:25:20,513: <INFO> =================================================================
2020-10-06 18:25:20,515: <INFO> Total params: 2,067
2020-10-06 18:25:20,515: <INFO> Trainable params: 1,630
2020-10-06 18:25:20,515: <INFO> Non-trainable params: 437
2020-10-06 18:25:20,516: <INFO> _________________________________________________________________
2020-10-06 18:25:23,618: <INFO> Epoch 0, loss 0.009070, change 0.009070, grad norm 0.030004
2020-10-06 18:25:27,797: <INFO> Epoch 20, loss 0.000705, change 0.008365, grad norm 0.000965
2020-10-06 18:25:31,962: <INFO> Epoch 40, loss 0.000495, change 0.000211, grad norm 0.000843
2020-10-06 18:25:36,103: <INFO> Epoch 60, loss 0.000416, change 0.000078, grad norm 0.000608
2020-10-06 18:25:40,231: <INFO> Epoch 80, loss 0.000380, change 0.000037, grad norm 0.001308
2020-10-06 18:25:44,360: <INFO> Epoch 100, loss 0.000344, change 0.000035, grad norm 0.001734
2020-10-06 18:25:48,482: <INFO> Epoch 120, loss 0.000317, change 0.000027, grad norm 0.001670
2020-10-06 18:25:52,593: <INFO> Epoch 140, loss 0.000298, change 0.000019, grad norm 0.001604
2020-10-06 18:25:56,734: <INFO> Epoch 160, loss 0.000283, change 0.000015, grad norm 0.002211
2020-10-06 18:26:00,873: <INFO> Epoch 180, loss 0.000269, change 0.000014, grad norm 0.001714
2020-10-06 18:26:04,985: <INFO> Epoch 200, loss 0.000268, change 0.000001, grad norm 0.003436
2020-10-06 18:26:09,119: <INFO> Epoch 220, loss 0.000254, change 0.000014, grad norm 0.002415
2020-10-06 18:26:13,248: <INFO> Epoch 240, loss 0.000273, change -0.000020, grad norm 0.005441
2020-10-06 18:26:17,366: <INFO> Epoch 260, loss 0.000257, change 0.000017, grad norm 0.004324
2020-10-06 18:26:21,496: <INFO> Epoch 280, loss 0.000233, change 0.000024, grad norm 0.001202
2020-10-06 18:26:25,673: <INFO> Epoch 300, loss 0.000230, change 0.000004, grad norm 0.001366
2020-10-06 18:26:29,809: <INFO> Epoch 320, loss 0.000231, change -0.000002, grad norm 0.002350
2020-10-06 18:26:33,947: <INFO> Epoch 340, loss 0.000237, change -0.000005, grad norm 0.003564
2020-10-06 18:26:38,102: <INFO> Epoch 360, loss 0.000226, change 0.000011, grad norm 0.001756
2020-10-06 18:26:42,232: <INFO> Epoch 380, loss 0.000223, change 0.000002, grad norm 0.001654
2020-10-06 18:26:42,800: <INFO> Training autoencoder v3: attempt 1
2020-10-06 18:26:42,801: <INFO> Model: "autoencoder-v3"
2020-10-06 18:26:42,801: <INFO> _________________________________________________________________
2020-10-06 18:26:42,801: <INFO> Layer (type)                 Output Shape              Param #   
2020-10-06 18:26:42,802: <INFO> =================================================================
2020-10-06 18:26:42,803: <INFO> conv1 (Conv2D)               (None, 32, 32, 4)         52        
2020-10-06 18:26:42,803: <INFO> _________________________________________________________________
2020-10-06 18:26:42,804: <INFO> conv1-leaky (LeakyReLU)      (None, 32, 32, 4)         0         
2020-10-06 18:26:42,805: <INFO> _________________________________________________________________
2020-10-06 18:26:42,806: <INFO> conv2 (Conv2D)               (None, 16, 16, 10)        170       
2020-10-06 18:26:42,806: <INFO> _________________________________________________________________
2020-10-06 18:26:42,807: <INFO> conv2-leaky (LeakyReLU)      (None, 16, 16, 10)        0         
2020-10-06 18:26:42,807: <INFO> _________________________________________________________________
2020-10-06 18:26:42,809: <INFO> conv3 (Conv2D)               (None, 8, 8, 20)          820       
2020-10-06 18:26:42,809: <INFO> _________________________________________________________________
2020-10-06 18:26:42,810: <INFO> conv3-leaky (LeakyReLU)      (None, 8, 8, 20)          0         
2020-10-06 18:26:42,810: <INFO> _________________________________________________________________
2020-10-06 18:26:42,811: <INFO> deconv3 (Conv2DTranspose)    (None, 16, 16, 10)        810       
2020-10-06 18:26:42,812: <INFO> _________________________________________________________________
2020-10-06 18:26:42,812: <INFO> deconv3-leaky (LeakyReLU)    (None, 16, 16, 10)        0         
2020-10-06 18:26:42,813: <INFO> _________________________________________________________________
2020-10-06 18:26:42,814: <INFO> deconv2 (Conv2DTranspose)    (None, 32, 32, 4)         164       
2020-10-06 18:26:42,814: <INFO> _________________________________________________________________
2020-10-06 18:26:42,815: <INFO> deconv2-leaky (LeakyReLU)    (None, 32, 32, 4)         0         
2020-10-06 18:26:42,816: <INFO> _________________________________________________________________
2020-10-06 18:26:42,817: <INFO> deconv1 (Conv2DTranspose)    (None, 64, 64, 3)         51        
2020-10-06 18:26:42,817: <INFO> _________________________________________________________________
2020-10-06 18:26:42,819: <INFO> deconv1-sigmoid (Activation) (None, 64, 64, 3)         0         
2020-10-06 18:26:42,819: <INFO> =================================================================
2020-10-06 18:26:42,822: <INFO> Total params: 2,067
2020-10-06 18:26:42,822: <INFO> Trainable params: 1,630
2020-10-06 18:26:42,822: <INFO> Non-trainable params: 437
2020-10-06 18:26:42,823: <INFO> _________________________________________________________________
2020-10-06 18:26:43,880: <INFO> Epoch 0, loss 0.013333, change 0.013333, grad norm 0.047916
2020-10-06 18:26:48,016: <INFO> Epoch 20, loss 0.000711, change 0.012623, grad norm 0.000417
2020-10-06 18:26:52,143: <INFO> Epoch 40, loss 0.000541, change 0.000169, grad norm 0.000425
2020-10-06 18:26:56,279: <INFO> Epoch 60, loss 0.000452, change 0.000089, grad norm 0.000409
2020-10-06 18:27:00,435: <INFO> Epoch 80, loss 0.000397, change 0.000055, grad norm 0.000383
2020-10-06 18:27:04,583: <INFO> Epoch 100, loss 0.000363, change 0.000034, grad norm 0.002021
2020-10-06 18:27:08,732: <INFO> Epoch 120, loss 0.000337, change 0.000026, grad norm 0.001136
2020-10-06 18:27:12,890: <INFO> Epoch 140, loss 0.000318, change 0.000019, grad norm 0.001483
2020-10-06 18:27:17,055: <INFO> Epoch 160, loss 0.000301, change 0.000016, grad norm 0.002539
2020-10-06 18:27:21,231: <INFO> Epoch 180, loss 0.000277, change 0.000024, grad norm 0.001658
2020-10-06 18:27:25,399: <INFO> Epoch 200, loss 0.000263, change 0.000013, grad norm 0.002213
2020-10-06 18:27:29,566: <INFO> Epoch 220, loss 0.000247, change 0.000016, grad norm 0.000989
2020-10-06 18:27:33,728: <INFO> Epoch 240, loss 0.000247, change 0.000000, grad norm 0.002707
2020-10-06 18:27:37,893: <INFO> Epoch 260, loss 0.000240, change 0.000007, grad norm 0.002617
2020-10-06 18:27:42,066: <INFO> Epoch 280, loss 0.000231, change 0.000009, grad norm 0.001411
2020-10-06 18:27:46,238: <INFO> Epoch 300, loss 0.000238, change -0.000007, grad norm 0.003397
2020-10-06 18:27:50,437: <INFO> Epoch 320, loss 0.000225, change 0.000013, grad norm 0.001160
2020-10-06 18:27:54,628: <INFO> Epoch 340, loss 0.000228, change -0.000003, grad norm 0.002319
2020-10-06 18:27:58,853: <INFO> Epoch 360, loss 0.000224, change 0.000004, grad norm 0.001714
2020-10-06 18:28:03,019: <INFO> Epoch 380, loss 0.000223, change 0.000002, grad norm 0.001746
2020-10-06 18:28:04,186: <INFO> Training autoencoder v3: attempt 2
2020-10-06 18:28:04,186: <INFO> Model: "autoencoder-v3"
2020-10-06 18:28:04,187: <INFO> _________________________________________________________________
2020-10-06 18:28:04,187: <INFO> Layer (type)                 Output Shape              Param #   
2020-10-06 18:28:04,188: <INFO> =================================================================
2020-10-06 18:28:04,189: <INFO> conv1 (Conv2D)               (None, 32, 32, 4)         52        
2020-10-06 18:28:04,190: <INFO> _________________________________________________________________
2020-10-06 18:28:04,191: <INFO> conv1-leaky (LeakyReLU)      (None, 32, 32, 4)         0         
2020-10-06 18:28:04,192: <INFO> _________________________________________________________________
2020-10-06 18:28:04,193: <INFO> conv2 (Conv2D)               (None, 16, 16, 10)        170       
2020-10-06 18:28:04,193: <INFO> _________________________________________________________________
2020-10-06 18:28:04,194: <INFO> conv2-leaky (LeakyReLU)      (None, 16, 16, 10)        0         
2020-10-06 18:28:04,194: <INFO> _________________________________________________________________
2020-10-06 18:28:04,195: <INFO> conv3 (Conv2D)               (None, 8, 8, 20)          820       
2020-10-06 18:28:04,196: <INFO> _________________________________________________________________
2020-10-06 18:28:04,198: <INFO> conv3-leaky (LeakyReLU)      (None, 8, 8, 20)          0         
2020-10-06 18:28:04,198: <INFO> _________________________________________________________________
2020-10-06 18:28:04,200: <INFO> deconv3 (Conv2DTranspose)    (None, 16, 16, 10)        810       
2020-10-06 18:28:04,200: <INFO> _________________________________________________________________
2020-10-06 18:28:04,201: <INFO> deconv3-leaky (LeakyReLU)    (None, 16, 16, 10)        0         
2020-10-06 18:28:04,201: <INFO> _________________________________________________________________
2020-10-06 18:28:04,203: <INFO> deconv2 (Conv2DTranspose)    (None, 32, 32, 4)         164       
2020-10-06 18:28:04,203: <INFO> _________________________________________________________________
2020-10-06 18:28:04,204: <INFO> deconv2-leaky (LeakyReLU)    (None, 32, 32, 4)         0         
2020-10-06 18:28:04,204: <INFO> _________________________________________________________________
2020-10-06 18:28:04,206: <INFO> deconv1 (Conv2DTranspose)    (None, 64, 64, 3)         51        
2020-10-06 18:28:04,207: <INFO> _________________________________________________________________
2020-10-06 18:28:04,208: <INFO> deconv1-sigmoid (Activation) (None, 64, 64, 3)         0         
2020-10-06 18:28:04,209: <INFO> =================================================================
2020-10-06 18:28:04,212: <INFO> Total params: 2,067
2020-10-06 18:28:04,212: <INFO> Trainable params: 1,630
2020-10-06 18:28:04,212: <INFO> Non-trainable params: 437
2020-10-06 18:28:04,213: <INFO> _________________________________________________________________
2020-10-06 18:28:05,266: <INFO> Epoch 0, loss 0.010585, change 0.010585, grad norm 0.033521
2020-10-06 18:28:09,389: <INFO> Epoch 20, loss 0.000698, change 0.009887, grad norm 0.000499
2020-10-06 18:28:13,495: <INFO> Epoch 40, loss 0.000551, change 0.000147, grad norm 0.000912
2020-10-06 18:28:17,618: <INFO> Epoch 60, loss 0.000455, change 0.000096, grad norm 0.000788
2020-10-06 18:28:21,727: <INFO> Epoch 80, loss 0.000389, change 0.000066, grad norm 0.000619
2020-10-06 18:28:25,840: <INFO> Epoch 100, loss 0.000351, change 0.000038, grad norm 0.001983
2020-10-06 18:28:29,959: <INFO> Epoch 120, loss 0.000326, change 0.000025, grad norm 0.001327
2020-10-06 18:28:34,098: <INFO> Epoch 140, loss 0.000310, change 0.000016, grad norm 0.000736
2020-10-06 18:28:38,222: <INFO> Epoch 160, loss 0.000305, change 0.000005, grad norm 0.002920
2020-10-06 18:28:42,348: <INFO> Epoch 180, loss 0.000285, change 0.000019, grad norm 0.001494
2020-10-06 18:28:46,465: <INFO> Epoch 200, loss 0.000295, change -0.000010, grad norm 0.004660
2020-10-06 18:28:50,596: <INFO> Epoch 220, loss 0.000274, change 0.000021, grad norm 0.003290
2020-10-06 18:28:54,723: <INFO> Epoch 240, loss 0.000267, change 0.000008, grad norm 0.003363
2020-10-06 18:28:58,855: <INFO> Epoch 260, loss 0.000255, change 0.000012, grad norm 0.002380
2020-10-06 18:29:02,990: <INFO> Epoch 280, loss 0.000247, change 0.000007, grad norm 0.002765
2020-10-06 18:29:07,119: <INFO> Epoch 300, loss 0.000242, change 0.000005, grad norm 0.002728
2020-10-06 18:29:11,239: <INFO> Epoch 320, loss 0.000230, change 0.000012, grad norm 0.001117
2020-10-06 18:29:15,369: <INFO> Epoch 340, loss 0.000236, change -0.000006, grad norm 0.002752
2020-10-06 18:29:19,510: <INFO> Epoch 360, loss 0.000227, change 0.000010, grad norm 0.001301
2020-10-06 18:29:23,648: <INFO> Epoch 380, loss 0.000234, change -0.000008, grad norm 0.002539
2020-10-06 18:29:26,955: <INFO> Assets written to: model\v3\assets
2020-10-06 18:29:27,012: <INFO> Best loss is 0.000222
2020-10-06 18:29:46,033: <INFO> max loss is 0.016928
