2020-10-06 20:39:15,525: <INFO> Training autoencoder v1: attempt 0
2020-10-06 20:39:15,526: <INFO> Model: "autoencoder-v1"
2020-10-06 20:39:15,528: <INFO> _________________________________________________________________
2020-10-06 20:39:15,531: <INFO> Layer (type)                 Output Shape              Param #   
2020-10-06 20:39:15,531: <INFO> =================================================================
2020-10-06 20:39:15,533: <INFO> conv1 (Conv2D)               (None, 32, 32, 7)         91        
2020-10-06 20:39:15,534: <INFO> _________________________________________________________________
2020-10-06 20:39:15,535: <INFO> conv1-leaky (LeakyReLU)      (None, 32, 32, 7)         0         
2020-10-06 20:39:15,535: <INFO> _________________________________________________________________
2020-10-06 20:39:15,536: <INFO> deconv1 (Conv2DTranspose)    (None, 64, 64, 3)         87        
2020-10-06 20:39:15,537: <INFO> _________________________________________________________________
2020-10-06 20:39:15,537: <INFO> deconv1-sigmoid (Activation) (None, 64, 64, 3)         0         
2020-10-06 20:39:15,537: <INFO> =================================================================
2020-10-06 20:39:15,539: <INFO> Total params: 178
2020-10-06 20:39:15,539: <INFO> Trainable params: 178
2020-10-06 20:39:15,539: <INFO> Non-trainable params: 0
2020-10-06 20:39:15,540: <INFO> _________________________________________________________________
2020-10-06 20:39:18,495: <INFO> Epoch 0, loss 0.014842, change 0.014842, grad norm 0.004763, lr 0.010000
2020-10-06 20:39:22,752: <INFO> Epoch 20, loss 0.000308, change 0.014534, grad norm 0.000823, lr 0.010000
2020-10-06 20:39:26,961: <INFO> Epoch 40, loss 0.000153, change 0.000156, grad norm 0.001136, lr 0.010000
2020-10-06 20:39:31,038: <INFO> Epoch 60, loss 0.000132, change 0.000020, grad norm 0.000753, lr 0.010000
2020-10-06 20:39:35,114: <INFO> Epoch 80, loss 0.000100, change 0.000032, grad norm 0.001939, lr 0.010000
2020-10-06 20:39:39,271: <INFO> Epoch 100, loss 0.000070, change 0.000030, grad norm 0.001705, lr 0.010000
2020-10-06 20:39:43,393: <INFO> Epoch 120, loss 0.000056, change 0.000014, grad norm 0.001206, lr 0.010000
2020-10-06 20:39:47,552: <INFO> Epoch 140, loss 0.000039, change 0.000017, grad norm 0.000729, lr 0.010000
2020-10-06 20:39:51,632: <INFO> Epoch 160, loss 0.000027, change 0.000012, grad norm 0.001302, lr 0.010000
2020-10-06 20:39:55,699: <INFO> Epoch 180, loss 0.000022, change 0.000006, grad norm 0.000271, lr 0.010000
2020-10-06 20:39:59,853: <INFO> Epoch 200, loss 0.000021, change 0.000001, grad norm 0.000341, lr 0.005000
2020-10-06 20:40:03,963: <INFO> Epoch 220, loss 0.000020, change 0.000000, grad norm 0.000144, lr 0.002500
2020-10-06 20:40:05,661: <INFO> Training autoencoder v1: attempt 1
2020-10-06 20:40:05,661: <INFO> Model: "autoencoder-v1"
2020-10-06 20:40:05,661: <INFO> _________________________________________________________________
2020-10-06 20:40:05,662: <INFO> Layer (type)                 Output Shape              Param #   
2020-10-06 20:40:05,662: <INFO> =================================================================
2020-10-06 20:40:05,664: <INFO> conv1 (Conv2D)               (None, 32, 32, 7)         91        
2020-10-06 20:40:05,665: <INFO> _________________________________________________________________
2020-10-06 20:40:05,666: <INFO> conv1-leaky (LeakyReLU)      (None, 32, 32, 7)         0         
2020-10-06 20:40:05,666: <INFO> _________________________________________________________________
2020-10-06 20:40:05,667: <INFO> deconv1 (Conv2DTranspose)    (None, 64, 64, 3)         87        
2020-10-06 20:40:05,668: <INFO> _________________________________________________________________
2020-10-06 20:40:05,669: <INFO> deconv1-sigmoid (Activation) (None, 64, 64, 3)         0         
2020-10-06 20:40:05,669: <INFO> =================================================================
2020-10-06 20:40:05,671: <INFO> Total params: 178
2020-10-06 20:40:05,671: <INFO> Trainable params: 178
2020-10-06 20:40:05,671: <INFO> Non-trainable params: 0
2020-10-06 20:40:05,672: <INFO> _________________________________________________________________
2020-10-06 20:40:06,482: <INFO> Epoch 0, loss 0.015167, change 0.015167, grad norm 0.005714, lr 0.010000
2020-10-06 20:40:10,595: <INFO> Epoch 20, loss 0.000399, change 0.014768, grad norm 0.000627, lr 0.010000
2020-10-06 20:40:14,698: <INFO> Epoch 40, loss 0.000200, change 0.000198, grad norm 0.001453, lr 0.010000
2020-10-06 20:40:18,836: <INFO> Epoch 60, loss 0.000158, change 0.000043, grad norm 0.000385, lr 0.010000
2020-10-06 20:40:22,961: <INFO> Epoch 80, loss 0.000082, change 0.000076, grad norm 0.001030, lr 0.010000
2020-10-06 20:40:27,075: <INFO> Epoch 100, loss 0.000081, change 0.000001, grad norm 0.002684, lr 0.010000
2020-10-06 20:40:31,213: <INFO> Epoch 120, loss 0.000080, change 0.000002, grad norm 0.002556, lr 0.005000
2020-10-06 20:40:35,328: <INFO> Epoch 140, loss 0.000073, change 0.000006, grad norm 0.000380, lr 0.005000
2020-10-06 20:40:39,423: <INFO> Epoch 160, loss 0.000072, change 0.000001, grad norm 0.000448, lr 0.002500
2020-10-06 20:40:43,545: <INFO> Epoch 180, loss 0.000072, change 0.000001, grad norm 0.000120, lr 0.001250
2020-10-06 20:40:44,438: <INFO> Training autoencoder v1: attempt 2
2020-10-06 20:40:44,438: <INFO> Model: "autoencoder-v1"
2020-10-06 20:40:44,439: <INFO> _________________________________________________________________
2020-10-06 20:40:44,439: <INFO> Layer (type)                 Output Shape              Param #   
2020-10-06 20:40:44,440: <INFO> =================================================================
2020-10-06 20:40:44,441: <INFO> conv1 (Conv2D)               (None, 32, 32, 7)         91        
2020-10-06 20:40:44,441: <INFO> _________________________________________________________________
2020-10-06 20:40:44,443: <INFO> conv1-leaky (LeakyReLU)      (None, 32, 32, 7)         0         
2020-10-06 20:40:44,443: <INFO> _________________________________________________________________
2020-10-06 20:40:44,444: <INFO> deconv1 (Conv2DTranspose)    (None, 64, 64, 3)         87        
2020-10-06 20:40:44,445: <INFO> _________________________________________________________________
2020-10-06 20:40:44,446: <INFO> deconv1-sigmoid (Activation) (None, 64, 64, 3)         0         
2020-10-06 20:40:44,446: <INFO> =================================================================
2020-10-06 20:40:44,448: <INFO> Total params: 178
2020-10-06 20:40:44,448: <INFO> Trainable params: 178
2020-10-06 20:40:44,448: <INFO> Non-trainable params: 0
2020-10-06 20:40:44,450: <INFO> _________________________________________________________________
2020-10-06 20:40:45,258: <INFO> Epoch 0, loss 0.014136, change 0.014136, grad norm 0.005994, lr 0.010000
2020-10-06 20:40:49,348: <INFO> Epoch 20, loss 0.000277, change 0.013859, grad norm 0.000725, lr 0.010000
2020-10-06 20:40:53,441: <INFO> Epoch 40, loss 0.000121, change 0.000157, grad norm 0.001175, lr 0.010000
2020-10-06 20:40:57,626: <INFO> Epoch 60, loss 0.000080, change 0.000040, grad norm 0.001321, lr 0.010000
2020-10-06 20:41:01,743: <INFO> Epoch 80, loss 0.000073, change 0.000007, grad norm 0.001735, lr 0.010000
2020-10-06 20:41:05,845: <INFO> Epoch 100, loss 0.000068, change 0.000005, grad norm 0.002546, lr 0.010000
2020-10-06 20:41:09,950: <INFO> Epoch 120, loss 0.000052, change 0.000016, grad norm 0.000509, lr 0.010000
2020-10-06 20:41:14,089: <INFO> Epoch 140, loss 0.000045, change 0.000006, grad norm 0.001054, lr 0.010000
2020-10-06 20:41:18,222: <INFO> Epoch 160, loss 0.000045, change 0.000001, grad norm 0.002084, lr 0.010000
2020-10-06 20:41:22,331: <INFO> Epoch 180, loss 0.000043, change 0.000001, grad norm 0.002117, lr 0.010000
2020-10-06 20:41:26,434: <INFO> Epoch 200, loss 0.000045, change -0.000001, grad norm 0.002401, lr 0.010000
2020-10-06 20:41:30,546: <INFO> Epoch 220, loss 0.000039, change 0.000006, grad norm 0.000593, lr 0.005000
2020-10-06 20:41:31,095: <WARNING> From C:\Users\Teucros\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\training\tracking\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
2020-10-06 20:41:31,109: <WARNING> From C:\Users\Teucros\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\training\tracking\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
2020-10-06 20:41:32,143: <INFO> Assets written to: model\v1\assets
2020-10-06 20:41:32,245: <INFO> Best loss is 0.000020
2020-10-06 20:42:02,362: <INFO> max loss is 0.013736
